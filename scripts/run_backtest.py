# scripts/run_backtest.py
# ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ìš© CLI (config.yaml + CLI override + ML ëª¨ë¸ ì—°ë™)

import argparse
import logging
import sys
from pathlib import Path
from typing import Any, Dict, List, Optional

import pandas as pd
import yaml
import joblib

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
PROJECT_ROOT = Path(__file__).resolve().parents[1]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from src.backtest.runner import BacktestRunner
from src.backtest.strategy import MLSignalStrategy, BuyAndHoldStrategy
from src.data.db_manager import DatabaseManager
from src.ml.logistic_regression import LogisticRegressionHandler
from src.data.pipeline import DataPipeline
from src.data.all_ticker import TickerUniverse

CONFIG_PATH = "config/backtest.yaml"


# ============================================
# ë¡œê¹… ì„¤ì •
# ============================================
def setup_logging(log_level: str = "INFO") -> logging.Logger:
    logging.basicConfig(
        level=getattr(logging, log_level.upper(), logging.INFO),
        format="%(asctime)s - %(levelname)s - %(message)s",
    )
    return logging.getLogger(__name__)


# ============================================
# ì„¤ì • ë¡œë”
# ============================================
def load_config(config_path: str = "config/config.yaml") -> Dict[str, Any]:
    """config.yaml ë¡œë“œ"""
    config_file = Path(config_path)
    if config_file.exists():
        with config_file.open("r", encoding="utf-8") as f:
            return yaml.safe_load(f) or {}
    return {}


# ============================================
# ML ì‹ í˜¸ ìƒì„±
# ============================================
def generate_ml_signals(
    df_dict: Dict[str,pd.DataFrame],
    model_path: str,
) -> Dict[str, pd.Series]:
    """
    í•™ìŠµëœ ML ëª¨ë¸ë¡œ ë§¤ìˆ˜ ì‹ í˜¸ ìƒì„±
    
    Args:
        df_dict: Dict[ticker, df of ticker]
            í‹°ì»¤ì™€ ê·¸ í‹°ì»¤ì— ëŒ€í•œ featureê°’ë“¤ì´ í¬í•¨ëœ DataFrame
        model_path: ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
    
    Returns:
        {ticker: pd.Series(index=date, values=0/1)} í˜•íƒœì˜ ì‹ í˜¸ ë”•ì…”ë„ˆë¦¬
    """
    logger = logging.getLogger(__name__)
    signals = {}
    
    # ëª¨ë¸ ë¡œë“œ
    if not Path(model_path).exists():
        logger.warning(f"ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        logger.warning("ì‹ í˜¸ ì—†ì´ ë°±í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤ (ëª¨ë“  ë‚ ì§œ signal=0)")
        return signals
    
    try:
        handler = joblib.load(model_path)
        logger.info(f"âœ“ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
    except Exception as e:
        logger.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return signals
    
    #í”¼ì³ ì»¬ëŸ¼ ë¶ˆëŸ¬ì˜¤ê¸°
    feature_columns = handler.feature_names

    #í‹°ì»¤ë¦¬ìŠ¤íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°
    ticker_list = list(df_dict.keys())

    logger.info(f"ğŸ“Š ì´ {len(ticker_list)}ê°œ í‹°ì»¤ì— ëŒ€í•´ ML ì‹ í˜¸ ìƒì„± ì‹œì‘")
    success_count = 0
    fail_count = 0

    for ticker in ticker_list:
        try:
            df = df_dict[ticker]

            # ML ì…ë ¥ê°’ ì„ íƒ
            X = df[feature_columns]

            # NaN ê²€ì‚¬
            if X.isnull().any().any():
                nan_count = X.isnull().sum().sum()
                nan_cols = X.isnull().any()
                nan_cols = nan_cols[nan_cols].index.tolist()
                raise ValueError(f"{ticker}: NaN ë°œê²¬ (ì´ {nan_count}ê°œ, ì»¬ëŸ¼: {nan_cols})")

            # ì˜ˆì¸¡
            predictions = handler.predict(X,threshold = 0.57)
            
            # ì‹ í˜¸ ì‹œë¦¬ì¦ˆ ìƒì„±
            signal_series = pd.Series(
                predictions,
                index=pd.to_datetime(df['date']),
                name='signal'
            )
            
            signals[ticker] = signal_series
            
            # í†µê³„ ì¶œë ¥
            buy_signals = (signal_series == 1).sum()
            total_days = len(signal_series)
            logger.info(f"{ticker}: {buy_signals}/{total_days} ë§¤ìˆ˜ ì‹ í˜¸ ({buy_signals/total_days:.1%})")
            success_count += 1

        except Exception as e:
            logger.warning(f"{ticker}: ì‹ í˜¸ ìƒì„± ì‹¤íŒ¨ - {e}")
            fail_count += 1
            continue

    logger.info(f"âœ… ì‹ í˜¸ ìƒì„± ì™„ë£Œ - ì„±ê³µ: {success_count}ê°œ, ì‹¤íŒ¨: {fail_count}ê°œ")
    return signals

# ============================================
# ë©”ì¸ ì‹¤í–‰
# ============================================
def main():
    # ============================
    # ë³€ìˆ˜ ì„¤ì • (Config ë¡œë“œ)
    # ============================

    # Config ë¡œë“œ
    config = load_config(CONFIG_PATH)

    # ë¡œê·¸ ì„¤ì •
    logger = setup_logging(config['log_level'])

    # 1.ë°ì´í„° ë¡œë“œ
    data_config = config['data']

    db_path = data_config['db_path']
    ticker_codes = TickerUniverse().get(['KOSPI'])[:50]

    # ì„ì‹œ: ë°ì´í„° ë¶€ì¡±í•œ ì¢…ëª© ì œì™¸
    #exclude_tickers = ['499790.KS', '017860.KS']
    #ticker_codes = [t for t in ticker_codes if t not in exclude_tickers]

    #ì„ì‹œ
    #data_config['ticker_codes']
    start_date = data_config['start_date']
    end_date = data_config['end_date']
    indicator_list = data_config['indicator_list']

    # 2.ML ì‹ í˜¸ ìƒì„±
    ml_config = config['ml']

    model_path = ml_config['model_path']

    # 3.backtest ë³€ìˆ˜
        # (1) ê¸°ë³¸ ë³€ìˆ˜
    basic_params = config['backtest']['basic_params']

    initial_cash = basic_params['initial_cash']
    commission = basic_params['commission']
    slippage = basic_params['slippage']
        # (2) Strategy ì „ìš© ë³€ìˆ˜
    strategy_params = config['backtest']['strategy_params']

    #ê¸°íƒ€
    output_csv = config['output_csv']
    
    logger.info(f"\n{'='*60}")
    logger.info("ğŸš€ ë°±í…ŒìŠ¤íŠ¸ ì„¤ì •")
    logger.info(f"{'='*60}")
    logger.info(f"ì¢…ëª©: {ticker_codes}")
    logger.info(f"ê¸°ê°„: {start_date} ~ {end_date}")
    logger.info(f"ì´ˆê¸° ìë³¸: {initial_cash:,.0f}")
    logger.info(f"ìˆ˜ìˆ˜ë£Œ: {commission:.4%}")
    logger.info(f"ìŠ¬ë¦¬í”¼ì§€: {slippage:.4%}")
    
    try:
        # ============ DataFrame ë¡œë“œ =============
        pipeline = DataPipeline(db_path=db_path)
        df_dict = pipeline.run_full_pipeline(
            ticker_list=ticker_codes,
            start_date=start_date,
            end_date=end_date,
            indicator_list=indicator_list,
        )

        # ============ ML ì‹ í˜¸ ìƒì„± ============
        signals = None
        strategy_class = MLSignalStrategy
        
        logger.info(f"\nğŸ¤– ML ëª¨ë¸ë¡œ ì‹ í˜¸ ìƒì„± ì¤‘...")
        signals = generate_ml_signals(
            model_path=model_path,
            df_dict=df_dict,
        )
            
        if not signals:
            logger.warning("MLì‹ í˜¸ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            raise ValueError(
                f"ML ì‹ í˜¸ ìƒì„± ê³¼ì •ì—ì„œ ë¬¸ì œê°€ ìƒê²¼ìŠµë‹ˆë‹¤!!"
            )

        # ============ dfì™€ signal í†µí•© =============
        logger.info("\nğŸ”— DataFrameê³¼ ML ì‹ í˜¸ ë³‘í•© ì¤‘...")

        # ì‹ í˜¸ê°€ ìˆëŠ” í‹°ì»¤ë§Œ ì²˜ë¦¬í•  ìƒˆë¡œìš´ df_dict ìƒì„±
        updated_df_dict = {}

        for ticker in ticker_codes:
            #ì„ì‹œ
            # df_dictì— ì—†ëŠ” í‹°ì»¤ëŠ” ê±´ë„ˆë›°ê¸° (ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°)
            if ticker not in df_dict:
                logger.warning(f"{ticker}: df_dictì— ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤")
                continue

            df = df_dict[ticker]
            signal = signals.get(ticker)

            #ì„ì‹œ
            # ì‹ í˜¸ê°€ ì—†ëŠ” í‹°ì»¤ëŠ” ê±´ë„ˆë›°ê¸° (ë°±í…ŒìŠ¤íŠ¸ì—ì„œ ì œì™¸)
            if signal is None:
                logger.warning(f"{ticker}: ì‹ í˜¸ê°€ ì—†ì–´ ë°±í…ŒìŠ¤íŠ¸ì—ì„œ ì œì™¸í•©ë‹ˆë‹¤")
                continue

            # signalì€ DatetimeIndexë¥¼ ê°€ì§„ Series
            # dfëŠ” 'date' ì»¬ëŸ¼ì„ ê°€ì§„ DataFrame

            # signalì„ DataFrameìœ¼ë¡œ ë³€í™˜
            signal_df = signal.reset_index()

            # date íƒ€ì… ë§ì¶”ê¸°
            df['date'] = pd.to_datetime(df['date'])
            signal_df['date'] = pd.to_datetime(signal_df['date'])

            # ë³‘í•© (left join - dfì˜ ëª¨ë“  ë‚ ì§œ ìœ ì§€)
            df = pd.merge(df, signal_df, on='date', how='left')

            # NaNì´ ìˆìœ¼ë©´ 0ìœ¼ë¡œ ì±„ìš°ê¸° (ì‹ í˜¸ê°€ ì—†ëŠ” ë‚ ì€ ë§¤ìˆ˜í•˜ì§€ ì•ŠìŒ)
            df['signal'] = df['signal'].fillna(0)

            # ì—…ë°ì´íŠ¸ëœ df_dictì— ì €ì¥
            updated_df_dict[ticker] = df

        # ì›ë˜ df_dictë¥¼ ì—…ë°ì´íŠ¸ëœ ë²„ì „ìœ¼ë¡œ êµì²´
        df_dict = updated_df_dict

        logger.info(f"ì‹ í˜¸ ë³‘í•© ì™„ë£Œ: {len(df_dict)}ê°œ ì¢…ëª©")
        
        # ============ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ============
        runner = BacktestRunner(
            db_path=db_path,
            initial_cash=initial_cash,
            commission=commission,
            slippage=slippage,
        )
        
        metrics = runner.run(
            df_dict = df_dict,
            strategy_class=strategy_class,
            strategy_params=strategy_params,
        )
        
        # ============ ê²°ê³¼ ì €ì¥ ============
        if output_csv:
            output_path = Path(output_csv)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
            results_df = pd.DataFrame([metrics.to_dict()])
            results_df.to_csv(output_path, index=False, encoding='utf-8-sig')
            logger.info(f"\nâœ“ ê²°ê³¼ ì €ì¥: {output_path}")
        
        logger.info("\nâœ… ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
    except KeyboardInterrupt:
        logger.warning("\nâ›” ì‚¬ìš©ì ì¤‘ë‹¨")
        sys.exit(0)
    except Exception as e:
        logger.error(f"\nâŒ ë°±í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    ticker_univ = TickerUniverse()
    kospi_all_ticker = ticker_univ.get(["KOSPI"])
    print(f"ì½”ìŠ¤í”¼ í‹°ì»¤ ê°œìˆ˜: {len(kospi_all_ticker)}")
    print(f"ì½”ìŠ¤í”¼ í‹°ì»¤ ë¦¬ìŠ¤íŠ¸ head: {kospi_all_ticker[50:]}")
    print(f"ì½”ìŠ¤í”¼ í‹°ì»¤ ë¦¬ìŠ¤íŠ¸ tail: {kospi_all_ticker[:-50]}")
    main()
