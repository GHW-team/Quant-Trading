import sys
import yaml
import logging
import pandas as pd
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€ (src ëª¨ë“ˆì„ ì°¾ê¸° ìœ„í•¨)
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.data.pipeline import DataPipeline
from src.ml.labeler import Labeler
from src.ml.logistic_regression import LogisticRegressionHandler

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)

def main():
    # 1. config.yaml ì½ê¸°
    config_path = Path(__file__).parent.parent / "config.yaml"
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)

    # ì„¤ì •ê°’ ì¶”ì¶œ (model ì„¹ì…˜ë§Œ ì‚¬ìš© - train_model.pyìš©)
    # database_pathëŠ” data ì„¹ì…˜ì—ì„œë§Œ ê°€ì ¸ì˜´ (DB ë¡œë“œìš©)
    database_path = config['data']['database_path']

    # model.training ì„¤ì •
    tickers = config['model']['training']['tickers']
    period = config['model']['training'].get('period')
    start_date = config['model']['training'].get('start_date')
    end_date = config['model']['training'].get('end_date')

    horizon = config['model']['labeling']['horizon']
    threshold = config['model']['labeling']['threshold']

    feature_columns = config['model']['features']['columns']
    indicator_list = config['model']['features']['indicators']

    output_dir = config['model']['output']['dir']
    output_file = config['model']['output']['file']
    output_path = f"{output_dir}/{output_file}"

    # ë³€ìˆ˜ ì •ì˜ (í¸ì˜ìƒ ëŒ€ë¬¸ì ìœ ì§€)
    FEATURE_COLUMNS = feature_columns
    INDICATOR_LIST = indicator_list

    logger.info(f"âœ… Config loaded from {config_path}")
    logger.info(f"   - Tickers: {tickers}")
    if period:
        logger.info(f"   - Period: {period}")
    else:
        logger.info(f"   - Date Range: {start_date} ~ {end_date}")
    logger.info(f"   - Horizon: {horizon}, Threshold: {threshold:.1%}")
    logger.info(f"   - Features: {FEATURE_COLUMNS}\n")

    # ==========================================
    # 2. ë°ì´í„° íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ë°ì´í„° ë¡œë“œ
    # ==========================================
    logger.info("2. Loading Data from Pipeline...")

    try:
        with DataPipeline(db_path=database_path) as pipeline:
            # DataPipelineì˜ run_full_pipeline ì‚¬ìš© (model.training ì„¤ì •ê°’ ì ìš©)
            pipeline_kwargs = {
                'ticker_list': tickers,
                'indicator_list': INDICATOR_LIST,
                'update_if_exists': True,
            }

            df_dict = pipeline.run_full_pipeline(
                ticker_list=tickers,
                indicator_list=INDICATOR_LIST,
                start_date=start_date,
                end_date=end_date,
                period=period,
            )

        if not df_dict:
            logger.error("âŒ DataPipelineì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
            sys.exit(1)

        # ëª¨ë“  ì¢…ëª©ì˜ ë°ì´í„°ë¥¼ í•˜ë‚˜ë¡œ ë³‘í•©
        dfs = list(df_dict.values())
        df_all = pd.concat(dfs, ignore_index=True)
        logger.info(f"   âœ“ Loaded {len(df_all)} records for {tickers}")

    except Exception as e:
        logger.error(f"âŒ DataPipeline ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        sys.exit(1)

    # ==========================================
    # 3. ë¼ë²¨ë§ (Labeling)
    # ==========================================
    logger.info(f"3. Labeling Data (Horizon={horizon}, Threshold={threshold:.1%})...")

    labeler = Labeler(horizon=horizon, threshold=threshold)
    df_labeled = labeler.label_data(df_all, price_col='adj_close')

    # ==========================================
    # 4. ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¶„í•  (Preprocessing)
    # ==========================================
    logger.info("4. Splitting & Cleaning Data...")

    # (1) NaN ì œê±°: Featureë‚˜ Labelì´ ì—†ëŠ” í–‰ì€ í•™ìŠµ ë¶ˆê°€
    # ModelHandlerì—ê²Œ ê¹¨ë—í•œ ë°ì´í„°ë¥¼ ì£¼ê¸° ìœ„í•œ í•„ìˆ˜ ê³¼ì •
    clean_data = df_labeled.dropna(subset=FEATURE_COLUMNS + ['label'])

    if clean_data.empty:
        logger.error("âŒ ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤ (ëª¨ë‘ NaN). ê¸°ê°„ì„ ëŠ˜ë ¤ë³´ì„¸ìš”.")
        sys.exit(1)

    # (2) Train / Test ë¶„í•  (ì‹œê³„ì—´ì´ë¯€ë¡œ ì„ì§€ ì•ŠìŒ)
    train_df, test_df = train_test_split(clean_data, test_size=0.2, shuffle=False)

    # (3) X, y ë¶„ë¦¬ (ModelHandler.train ì…ë ¥ìš©)
    X_train = train_df[FEATURE_COLUMNS]
    y_train = train_df['label']

    X_test = test_df[FEATURE_COLUMNS]
    y_test = test_df['label']

    logger.info(f"   - Train Samples: {len(train_df)}")
    logger.info(f"   - Test Samples:  {len(test_df)}")

    # ==========================================
    # 5. ëª¨ë¸ í•™ìŠµ (Training with Handler)
    # ==========================================
    logger.info("5. Initializing & Training ModelHandler...")

    handler = LogisticRegressionHandler(feature_names=FEATURE_COLUMNS)

    # [í•µì‹¬] GridSearch + TimeSeriesSplit êµì°¨ê²€ì¦ ìˆ˜í–‰
    handler.train(X_train, y_train)

    # ëª¨ë¸ ì €ì¥
    Path(output_path).parent.mkdir(parents=True, exist_ok=True)
    handler.save(output_path)
    logger.info(f"âœ… Model Saved: {output_path}")

    # ==========================================
    # 6. ìµœì¢… í‰ê°€ (Evaluation)
    # ==========================================
    logger.info("6. Evaluating on Test Set...")

    metrics = handler.evaluate(X_test, y_test)
    print(f"\nğŸ“Š Test Accuracy: {metrics['test_accuracy']:.4f}")
    
    # ìƒì„¸ ë¦¬í¬íŠ¸ ì¶œë ¥ (Precision, Recall ë“± í™•ì¸)
    # predict() ë©”ì„œë“œëŠ” Backtraderìš©ì´ì§€ë§Œ ì—¬ê¸°ì„œë„ ê²€ì¦ìš©ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥
    y_pred = handler.predict(test_df[FEATURE_COLUMNS])
    y_true = test_df['label']
    
    print("\n[Classification Report]")
    print(classification_report(y_true, y_pred))

if __name__ == "__main__":
    main()